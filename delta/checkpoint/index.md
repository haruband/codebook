델타레이크는 쓰기 작업이나 여러 최적화 과정(Compaction, Z-Order, ...)이 반복될수록 로그가 쌓여간다. 이렇게 로그가 지속적으로 쌓여가면 마지막 상태 정보를 담고 있는 스냅샷을 만드는 작업이 점점 더 오래 걸릴 수 밖에 없어진다. 이 문제를 개선하기 위해 델타레이크는 몇 가지 기능을 제공하고 있다. 오늘은 이에 대해 간단히 살펴보고자 한다.

## _지나간 로그 파일 정리_

로그 파일이 많아져도 스냅샷을 만들 때는 마지막 체크포인트 파일과 이후의 로그 파일만 사용되지만, 로그 파일이 많아지는 것 자체가 스토리지에 부담을 준다. 그래서 델타레이크는 일정 기간이 지난 로그 파일을 제거하는 기능을 제공하고 있다. 사용법은 아래와 같다.
(현재 S3 스토리지의 경우, 특정 버전 이후의 로그 파일을 가져오는 listFrom() 함수가 모든 로그 파일을 가져온 다음 필터링하는 방식으로 동작하고 있기 때문에 특히 문제가 심각하다. 하지만, 현재 이를 해결하기 위한 [PR](https://github.com/delta-io/delta/pull/1210)이 대기 중이다.)

```python
.config(
    "spark.databricks.delta.properties.defaults.logRetentionDuration",
    "interval 7 days",
)
```

해당 옵션의 기본값은 30 일이고, 위와 같이 7 일로 지정하면 체크포인트 파일을 만들 때마다 7 일이 지난 로그 파일들은 제거한다. 여기서 주의할 점은 마지막 체크포인트 이후의 로그 파일은 제거되지 않는다. 이유는 아직 해당 로그 파일의 내용이 어떤 체크포인트 파일에도 포함되지 않았기 때문이다. 그리고 또 한 가지 주의할 점은 해당 기간 이전으로는 롤백할 수 없게 된다. 이유는 롤백할 때 마지막 체크포인트부터 해당 버전까지의 로그 파일들이 필요하기 때문이다.

## _지워진 파일 로그 정리_

로그가 쌓이면 체크포인트 파일의 크기도 꾸준히 증가하기 때문에 스냅샷을 만들 때 문제가 될 수 있다. 이를 개선하기 위해서는 불필요한 로그를 꾸준히 없애주는 작업이 필요하다. 델타레이크는 데이터에 대한 변경이나 최적화를 할 때 기존 데이터 파일은 그대로 두고 새로운 데이터 파일을 추가하기 때문에 기존 데이터 파일은 롤백할 때를 제외하곤 필요없어진다. 그래서 아래와 같이 옵션을 지정하면 체크포인트 파일을 만들 때마다 해당 기간이 지난 불필요한 로그들은 제거된다. 여기서 말하는 불필요한 로그들은 데이터 파일을 삭제(remove)하는 로그와 해당 데이터 파일을 추가(add)했던 로그이다.

```python
.config(
    "spark.databricks.delta.properties.defaults.deletedFileRetentionDuration",
    "interval 0 days",
)
```

참고로, 델타레이크가 제공하는 Vacuum 명령어는 지정한 기간이 지난 불필요한 데이터 파일을 지우는 역할을 한다. 위의 기능과는 별개로 동작한다.

## _체크포인트 파일 쪼개기_
