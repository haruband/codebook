대표적인 빅데이터 처리 기술인 스파크(Spark)는 중간 결과를 하둡(Hadoop)처럼 디스크에 저장하지 않고 메모리에만 저장함으로써 놀랄만한 성능 개선을 가져왔다. 하지만 그만큼 메모리 사용량이 늘어났고, 메모리 관리를 어렵게 만들었다. 이는 다양한 서비스들과 스파크를 동시에 운영하는 쿠버네티스(K8S) 환경에서 더 심각한 문제가 될 수 있으며, 오늘은 최근 쿠버네티스에서도 지원하기 시작한 스왑(Swap)을 이용하여 이러한 문제를 어떻게 해결하였는지 소개하고자 한다.

우선 쿠버네티스 환경에서 스파크를 운영할 때 메모리 관련해서 발생하는 다양한 문제들에 대해 살펴보자.

## JVM OOM(Out-Of-Memory)

스칼라(Scala)로 개발된 스파크는 JVM 위에서 동작하기 때문에 JVM 이 사용할 최대 힙(Heap)의 크기를 지정해야 한다. 이 값이 실제 최대 사용량보다 작으면 OOM(JVM) 에 의해 해당 작업이 종료되고, 너무 크면 낭비되는 메모리가 많아질 수 있으니 적절한 값으로 설정하는 것이 중요하다.

## CGroup OOM(Out-Of-Memory)

스파크의 쿠버네티스 스케줄러는 익스큐터(Executor) 파드에 JVM 최대 힙 크기와 메모리 오버헤드 크기 등을 합쳐서 요청량(Requests)과 제한량(Limits)을 적용한다. 그래서 만약 해당 파드가 스왑 없이 익명 페이지를 메모리 한도보다 많이 사용한다면, OOM(CGroup) 에 의해 파드가 종료된다. 파드의 메모리 사용량이 많아지면 지속적으로 메모리를 반환하지만, 스왑이 없으면 익명 페이지는 반환되지 않기 때문이다. (스왑이 있으면 이론적으로는 OOM(CGroup) 은 발생하지 않는다.)

## Process OOM(Out-Of-Memory)

시스템의 물리 메모리가 부족해지면 커널에 의해 우선순위(oom_score)를 따라서 특정 프로세스가 종료(OOM)되기 시작한다. 쿠버네티스는 QoS 정책에 따라 우선순위(oom_score_adj)를 지정하기 때문에, 서비스의 중요도에 따라서 QoS 정책을 잘 세워야만 최악의 상황은 면할 수 있다.

## K8S PodEviction

시스템의 물리 메모리가 지정된 값보다 작아지면, Kubelet 은 주기적으로 우선순위가 낮은 파드를 종료시킨다. 기본 설정값이 10 초마다 물리 메모리가 100 MBytes 이하일 때 파드를 추출하는 것인데, 우리의 실험 환경에서는 Kubelet 에 의해 파드가 추출되는 경우는 한번도 없었고 모두 커널에 의해 OOM 으로 종료되었다. 기본 설정값을 변경하거나 실험 환경이 다르면 다른 결과를 보일 수도 있겠지만, 이러한 환경에서는 현실적으로 실효성이 없다고 볼 수 있다.

## SparkExecutor HeartbeatTimeout

스파크의 익스큐터는 주기적으로 드라이버에게 하트비트(Heartbeat)를 전송한다. 하지만 시스템의 물리 메모리가 심각하게 부족해지면 시스템 전체가 과부하 상태가 되면서 하트비트를 제대로 전송하지 못하는 경우가 생긴다. 이럴 경우, 스파크 드라이버는 해당 익스큐터를 강제로 재시작시킨다.

## K8S Node NotReady

시스템의 물리 메모리가 심각하게 부족해지면 시스템 전체가 과부하 상태가 되면서 노드가 동작불능(NotReady) 상태가 되고, 이 상태가 일정시간(PodEvictionTimeout) 이상 지속되면 해당 노드의 모든 파드가 추출된다.

지금까지 설명한 문제들은 크게 두 가지로 나뉜다. 첫 번째는 파드(익스큐터)에 충분한 메모리를 할당하지 않아서 발생하는 문제(JVM/CGroup OOM)이고, 두 번째는 전체 메모리 사용량이 시스템의 물리 메모리를 초과해서 발생하는 문제이다. 두 문제 모두 근본적인 원인은 서비스가 사용하는 메모리를 정확히 계산/예측하는 것이 매우 어렵다는 것이다. 그래서 문제가 발생하지 않을만큼 파드에 메모리를 할당하고 시스템에 물리 메모리를 추가하는 것이 일반적인 방법이지만, 이는 서비스가 지속적으로 재접근하는 메모리의 크기를 의미하는 워킹셋(WorkingSet)과 최대 메모리 사용량의 차이가 클수록 시스템의 활용률을 낮출 수 밖에 없다. 이를 개선하기 위해서는 꾸준히 재접근되지 않는 메모리를 반환해야 하는데, 스왑이 없으면 익명 페이지는 반환 자체를 할 수 없다.

스왑이 없으면 익명 페이지를 반환할 수 없는데, 왜 쿠버네티스는 그 동안 스왑을 허용하지 않았을까? 여러 가지 이유가 있겠지만, 과거부터 주로 언급되던 스왑의 문제는 전반적인 성능에 대한 불확실성을 높인다는 것이다. 하지만, 최근 디스크의 입출력 속도와 스왑 관련 리눅스 커널 코드가 많이 개선되었고, 다양한 사용자들이 꾸준히 요청해왔기 때문에 쿠버네티스에서도 공식적으로 스왑을 지원하게 되었다.

아래 그림은 노드의 허용량(Capacity)까지 스파크 스트리밍을 배포했을 때 주기적으로 노드가 동작불능 상태가 되면서 모든 파드가 추출된 상황을 보여주고 있다. (요청량이 없는 파드때문에 실제 사용량은 요청량을 초과한다.)

![memory.usages.without.swap.png](./memory.usages.without.swap.png)

시스템의 물리 메모리가 심각하게 부족해져서 커널이 특정 프로세스를 종료(OOM)시켜도 쿠버네티스가 해당 프로세스를 바로 재시작하고, 스파크의 익스큐터에 문제가 생겨도 드라이버가 익스큐터를 바로 재시작하기 때문에 결국은 노드가 동작불능 상태가 되어 모든 파드가 추출된다. 위의 실험에서도 불특정하게 커널이 프로세스를 종료하거나 스파크 드라이버가 익스큐터를 재시작하지만, 결국은 반복적으로 노드가 동작불능 상태가 된다.
